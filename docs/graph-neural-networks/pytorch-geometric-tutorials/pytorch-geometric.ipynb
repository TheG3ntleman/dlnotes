{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03891869",
   "metadata": {},
   "source": [
    "# What is pytorch geometric?\n",
    "Pytorch geometric is a library built on top of pytorch that aims to simplify the implementation of geometric deep learning models. First some motivation as to what geometric deep learning is.\n",
    "\n",
    "## Classical deep learning on graph-based data\n",
    "The naive approach to this problem is to find the adjacency matrix of a input graph and use that as input to a neural network as there are already several successful architectures that take matrices as input, primarily those related to computer vision (ex. convolutional neural networks, feed forward neural networks, ...). However, this approach has some problems:\n",
    "- Model cannot adapt to changes in graph size (I.E number of nodes). \n",
    "- The adjacency matrix is not permutation invariant (I.E one graph might have multiple distinct adjacency matrices).\n",
    "In many cases, not only is the structure of the graph important but also the properties of the nodes in a particular graph. Thus, in a general case, a network must also account for a secondary features matrix containing node related information.\n",
    "\n",
    "## Graph Neural Networks\n",
    "\n",
    "### The computation graph of a node\n",
    "Every node of a graph has a computation graph. The computation graph of a node is a tree where the root node is the node in question and it's children are it's neighbours. The neighbours in the child layer also have children (composed of the neighbours's neighbours). This process continuous until all nodes are exhuasted. **Node repetition is valid.**\n",
    "\n",
    "Sometimes, the process of generating the this computation graph layer by layer is informally referred to as unrolling the graph about a particular node. Often unrolling is limited to a particular number, this imposes a constraint on the depth of each computation graph.\n",
    "\n",
    "### Action on the computation graph of a node\n",
    "GNNs process graph-data using two mechanisms: aggregation and propagation. Starting from the leaf-nodes, data is supplied from the node-feature matrix. If multiple children share a parent, their information is combined through aggregation. The aggregated product is then transmitted to the parent, considering the parent's feature vector, via the propagation mechanism. This process continues until information reaches the root node.\n",
    "\n",
    "An important property of the aggregation mechanism is its permutation invariance, meaning it doesn't depend on the order of inputs supplied.\n",
    "\n",
    "### How much to unroll\n",
    "Unrolling too little can result in important information not being transmitted whereas unrolling too much makes computation far more expensive even though the information transmitted from distant nodes might not affect the overall result.\n",
    "\n",
    "### Computation formally described for a particular case\n",
    "The above computation can be consicely described by the following equations:\n",
    "$$\n",
    "\\begin{gather}\n",
    "H_v^0 = X_v \\\\ \n",
    "h_v^{k+1} = \\sigma\\bigg(W_k\\sum_{u\\in N(u)}\\frac{h_u^k}{|N(v)|} + B_kh_v^k\\bigg) \\\\ \n",
    "Z_v = h_v^K\n",
    "\\end{gather}\n",
    "$$\n",
    "where, $\\sigma$ is an activation function $W_k$ and $B_k$ are trainable weights, $N(u)$ is the set of neighbours of node $u$, and, $\\sum$ is some permutation invariant aggregation function. Keep in mind that this equation only comes after making a specific selection as to how the propagation mechanism acts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f43e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "255e5122",
   "metadata": {},
   "source": [
    "#  Graph SAGE\n",
    "\n",
    "Graph SAGE is a architecture that is mostly the same as the general GNN described above with the exception of the propagation and aggregation mechanism, which we describe here,\n",
    "$$h_v^{k+1} = \\sigma\\bigg(\\bigg[W_k\\cdot AGG\\bigg(\\{h_u^{k-1}, \\forall u\\in N(v)\\}\\bigg), B_kh_v^k\\bigg]\\bigg)$$\n",
    "where, $[,]$ is a concatenation and $AGG$ is a general aggregation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb967693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial - I code from this point on\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b54e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root=\"tutorial1\", name=\"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed793507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "number of graphs:\t\t 1\n",
      "number of classes:\t\t 7\n",
      "number of node features:\t 1433\n",
      "number of edge features:\t 0\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(\"number of graphs:\\t\\t\", len(dataset))\n",
    "print(\"number of classes:\\t\\t\", dataset.num_classes)\n",
    "print(\"number of node features:\\t\", dataset.num_node_features)\n",
    "print(\"number of edge features:\\t\", dataset.num_edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab21627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3a03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcc937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv = SAGEConv(dataset.num_features,\n",
    "                            dataset.num_classes,\n",
    "                            aggr = \"max\")\n",
    "        \n",
    "    def forward(self):\n",
    "        x = self.conv(data.x, data.edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "373919d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4dc3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2949985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Val: 0.7120, Test: 0.7340\n",
      "Epoch: 020, Val: 0.7120, Test: 0.7340\n",
      "Epoch: 030, Val: 0.7120, Test: 0.7340\n",
      "Epoch: 040, Val: 0.7120, Test: 0.7340\n",
      "Epoch: 050, Val: 0.7120, Test: 0.7340\n",
      "Epoch: 060, Val: 0.7120, Test: 0.7340\n",
      "Epoch: 070, Val: 0.7120, Test: 0.7340\n",
      "Epoch: 080, Val: 0.7120, Test: 0.7340\n",
      "Epoch: 090, Val: 0.7120, Test: 0.7340\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 100):\n",
    "    train()\n",
    "    _, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    log = 'Epoch: {:03d}, Val: {:.4f}, Test: {:.4f}'\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(log.format(epoch, best_val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43129159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66f30459",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [ Pytorch Geometric tutorial: Introduction to Pytorch geometric ](https://youtu.be/JtDgmmQ60x8)\n",
    "2. [Graph SAGE paper](https://cs.stanford.edu/people/jure/pubs/graphsage-nips17.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
